{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48cfa692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3f2d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score,roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn.base import BaseEstimator,ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbad92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(model):\n",
    "    \n",
    "    print(f'Доля верных ответов на обучающей выборки = {accuracy_score(y_train, model.predict(X_train))}')\n",
    "    print(f'Доля верных ответов на тестовой выборки = {accuracy_score(y_test, model.predict(X_test))}')\n",
    "    \n",
    "    print(f'Recall_score на обучающей выборки = {recall_score(y_train, model.predict(X_train))}')\n",
    "    print(f'Recall_score на тестовой выборки = {recall_score(y_test, model.predict(X_test))}')\n",
    "    \n",
    "    print(f'Precision_score на обучающей выборки = {precision_score(y_train, model.predict(X_train))}')\n",
    "    print(f'Precision_score на тестовой выборки = {precision_score(y_test, model.predict(X_test))}')\n",
    "    \n",
    "    print(f'Roc_auc_score на обучающей выборки = {roc_auc_score(y_train, model.predict(X_train))}')\n",
    "    print(f'Roc_auc_score на тестовой выборки = {roc_auc_score(y_test, model.predict(X_test))}')\n",
    "    \n",
    "    print(f'Confusion_matrix на обучающей выборки = \\n{confusion_matrix(y_train, model.predict(X_train))}')\n",
    "    print(f'Confusion_matrix на тестовой выборки = \\n{confusion_matrix(y_test, model.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a11537",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('remastered_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ac6a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(dataset.drop(['Survived'],axis=1)), np.array(dataset['Survived']), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f51e6",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe266730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_LogitRegression(BaseEstimator, ClassifierMixin):\n",
    "    def __init__( self, learning_rate=0.01, iterations=15000 ) :        \n",
    "        self.learning_rate = learning_rate        \n",
    "        self.iterations = iterations\n",
    "          \n",
    "    def fit( self, X, Y ) :        \n",
    "        self.m, self.n = X.shape        \n",
    "        self.W = np.zeros( self.n )        \n",
    "        self.b = 0        \n",
    "        self.X = X        \n",
    "        self.Y = Y\n",
    "          \n",
    "                  \n",
    "        for i in range( self.iterations ) :            \n",
    "            self.update_weights()            \n",
    "        return self\n",
    "      \n",
    "      \n",
    "    def update_weights( self ) :           \n",
    "        A = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) )\n",
    "          \n",
    "        tmp = ( A - self.Y.T )        \n",
    "        tmp = np.reshape( tmp, self.m )        \n",
    "        dW = np.dot( self.X.T, tmp ) / self.m         \n",
    "        db = np.sum( tmp ) / self.m \n",
    "          \n",
    "        self.W = self.W - self.learning_rate * dW    \n",
    "        self.b = self.b - self.learning_rate * db\n",
    "          \n",
    "        return self\n",
    "      \n",
    "      \n",
    "    def predict( self, X ) :    \n",
    "        Z = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )        \n",
    "        Y = np.where( Z > 0.5, 1, 0 )        \n",
    "        return Y\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57b18d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = My_LogitRegression()\n",
    "params = {'iterations':[100,500,1000,2000,5000,10000,15000],'learning_rate':[1,0.1,0.01,0.001,0.0001]}\n",
    "name = 'custom_LogitRegression'\n",
    "grid = GridSearchCV(estimator=model,param_grid =params,cv=3 )  \n",
    "grid.fit(X_train,y_train)\n",
    "with open(name+'_best_params.txt', 'a') as f:\n",
    "    f.write(str(grid.best_estimator_))\n",
    "    \n",
    "pkl_filename = name+'_best_model.pkl'\n",
    "    \n",
    "with open(pkl_filename, 'wb') as file: \n",
    "    pickle.dump(grid.best_estimator_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30933c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верных ответов на обучающей выборки = 0.7556179775280899\n",
      "Доля верных ответов на тестовой выборки = 0.776536312849162\n",
      "Recall_score на обучающей выборки = 0.4664179104477612\n",
      "Recall_score на тестовой выборки = 0.5540540540540541\n",
      "Precision_score на обучающей выборки = 0.8012820512820513\n",
      "Precision_score на тестовой выборки = 0.8541666666666666\n",
      "Roc_auc_score на обучающей выборки = 0.6982990453139708\n",
      "Roc_auc_score на тестовой выборки = 0.7436936936936936\n",
      "Confusion_matrix на обучающей выборки = \n",
      "[[413  31]\n",
      " [143 125]]\n",
      "Confusion_matrix на тестовой выборки = \n",
      "[[98  7]\n",
      " [33 41]]\n"
     ]
    }
   ],
   "source": [
    "metrics(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fbf8c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "params = {}\n",
    "name = 'sklearn_LogitRegression'\n",
    "grid = GridSearchCV(estimator=model,param_grid =params,cv=3 )  \n",
    "grid.fit(X_train,y_train)\n",
    "with open(name+'_best_params.txt', 'a') as f:\n",
    "    f.write(str(grid.best_estimator_))\n",
    "    \n",
    "pkl_filename = name+'_best_model.pkl'\n",
    "    \n",
    "with open(pkl_filename, 'wb') as file: \n",
    "    pickle.dump(grid.best_estimator_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b98a45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верных ответов на обучающей выборки = 0.800561797752809\n",
      "Доля верных ответов на тестовой выборки = 0.8044692737430168\n",
      "Recall_score на обучающей выборки = 0.6902985074626866\n",
      "Recall_score на тестовой выборки = 0.7432432432432432\n",
      "Precision_score на обучающей выборки = 0.7581967213114754\n",
      "Precision_score на тестовой выборки = 0.7746478873239436\n",
      "Roc_auc_score на обучающей выборки = 0.7787078122899019\n",
      "Roc_auc_score на тестовой выборки = 0.7954311454311453\n",
      "Confusion_matrix на обучающей выборки = \n",
      "[[385  59]\n",
      " [ 83 185]]\n",
      "Confusion_matrix на тестовой выборки = \n",
      "[[89 16]\n",
      " [19 55]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "metrics(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f75d88",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "447d5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, lr=0.001, lambda_param=0.01, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.lambda_param = lambda_param\n",
    "        self.n_iters = n_iters\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        y_ = np.where(y <= 0, -1, 1)\n",
    "        \n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                condition = y_[idx] * (np.dot(x_i, self.w) - self.b) >= 1\n",
    "                if condition:\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w)\n",
    "                else:\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, y_[idx]))\n",
    "                    self.b -= self.lr * y_[idx]\n",
    "\n",
    "\n",
    "    def predict_train(self, X):\n",
    "        approx = np.dot(X, self.w) - self.b\n",
    "        return np.sign(approx)\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \n",
    "        pred = self.predict_train(X)\n",
    "        for i in range(len(pred)):\n",
    "            \n",
    "            if pred[i]>=0:\n",
    "                pred[i]=1\n",
    "            else:\n",
    "                pred[i]=0\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cd5b3a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = SVM()\n",
    "params = {'n_iters':[100,500,1000],'lr':[1,0.1,0.01,0.001,0.0001],'lambda_param':[0.001,0.01,0.1]}\n",
    "name = 'custom_SVM()'\n",
    "grid = GridSearchCV(estimator=model,param_grid =params,cv=3 )  \n",
    "grid.fit(X_train,y_train)\n",
    "with open(name+'_best_params.txt', 'a') as f:\n",
    "    f.write(str(grid.best_estimator_))\n",
    "    \n",
    "pkl_filename = name+'_best_model.pkl'\n",
    "    \n",
    "with open(pkl_filename, 'wb') as file: \n",
    "    pickle.dump(grid.best_estimator_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f378bc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верных ответов на обучающей выборки = 0.7907303370786517\n",
      "Доля верных ответов на тестовой выборки = 0.7877094972067039\n",
      "Recall_score на обучающей выборки = 0.6305970149253731\n",
      "Recall_score на тестовой выборки = 0.6756756756756757\n",
      "Precision_score на обучающей выборки = 0.771689497716895\n",
      "Precision_score на тестовой выборки = 0.78125\n",
      "Roc_auc_score на обучающей выборки = 0.7589922011563803\n",
      "Roc_auc_score на тестовой выборки = 0.7711711711711712\n",
      "Confusion_matrix на обучающей выборки = \n",
      "[[394  50]\n",
      " [ 99 169]]\n",
      "Confusion_matrix на тестовой выборки = \n",
      "[[91 14]\n",
      " [24 50]]\n"
     ]
    }
   ],
   "source": [
    "metrics(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5995a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "params = {'C':[1,0.1,0.01]}\n",
    "name = 'sklearn_SVM()'\n",
    "grid = GridSearchCV(estimator=model,param_grid =params,cv=3 )  \n",
    "grid.fit(X_train,y_train)\n",
    "with open(name+'_best_params.txt', 'a') as f:\n",
    "    f.write(str(grid.best_estimator_))\n",
    "    \n",
    "pkl_filename = name+'_best_model.pkl'\n",
    "    \n",
    "with open(pkl_filename, 'wb') as file: \n",
    "    pickle.dump(grid.best_estimator_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f3cbdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верных ответов на обучающей выборки = 0.6699438202247191\n",
      "Доля верных ответов на тестовой выборки = 0.659217877094972\n",
      "Recall_score на обучающей выборки = 0.25\n",
      "Recall_score на тестовой выборки = 0.25675675675675674\n",
      "Precision_score на обучающей выборки = 0.6633663366336634\n",
      "Precision_score на тестовой выборки = 0.76\n",
      "Roc_auc_score на обучающей выборки = 0.5867117117117118\n",
      "Roc_auc_score на тестовой выборки = 0.5998069498069498\n",
      "Confusion_matrix на обучающей выборки = \n",
      "[[410  34]\n",
      " [201  67]]\n",
      "Confusion_matrix на тестовой выборки = \n",
      "[[99  6]\n",
      " [55 19]]\n"
     ]
    }
   ],
   "source": [
    "metrics(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112fd6c",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "871ed310",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self,k=3):\n",
    "        \n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self,x,y):\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def predict(self,x):\n",
    "        labels = []\n",
    "        for i in x:\n",
    "            labels.append(self._get_one_pred(i))\n",
    "            \n",
    "        return labels   \n",
    "    \n",
    "    def _get_one_pred(self,one_point):\n",
    "        lengths = {}\n",
    "        \n",
    "        for i in range(len(self.x)):\n",
    "            lengths[self._get_length(self.x[i],one_point)] = self.y[i]\n",
    "        \n",
    "        zero = 0\n",
    "        one = 0\n",
    "        \n",
    "        for i in sorted(list(lengths.keys()))[:self.k]:\n",
    "            if lengths[i] == 0:\n",
    "                \n",
    "                zero = zero + 1\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                one = one + 1\n",
    "            \n",
    "        if zero> one:\n",
    "            return 0\n",
    "            \n",
    "        else:\n",
    "                \n",
    "            return 1\n",
    "    \n",
    "    def _get_length(self,first_point,second_point):\n",
    "        \n",
    "        return math.sqrt(sum([(i - k)**2 for i,k in zip(first_point, second_point)]))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a108ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNN()\n",
    "params = {'k':[2,3,4,5]}\n",
    "name = 'custom_KNN()'\n",
    "grid = GridSearchCV(estimator=model,param_grid =params,cv=3 )  \n",
    "grid.fit(X_train,y_train)\n",
    "with open(name+'_best_params.txt', 'a') as f:\n",
    "    f.write(str(grid.best_estimator_))\n",
    "    \n",
    "pkl_filename = name+'_best_model.pkl'\n",
    "    \n",
    "with open(pkl_filename, 'wb') as file: \n",
    "    pickle.dump(grid.best_estimator_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d73dbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верных ответов на обучающей выборки = 0.7752808988764045\n",
      "Доля верных ответов на тестовой выборки = 0.7094972067039106\n",
      "Recall_score на обучающей выборки = 0.6305970149253731\n",
      "Recall_score на тестовой выборки = 0.527027027027027\n",
      "Precision_score на обучающей выборки = 0.7347826086956522\n",
      "Precision_score на тестовой выборки = 0.6964285714285714\n",
      "Roc_auc_score на обучающей выборки = 0.7466048137689929\n",
      "Roc_auc_score на тестовой выборки = 0.6825611325611326\n",
      "Confusion_matrix на обучающей выборки = \n",
      "[[383  61]\n",
      " [ 99 169]]\n",
      "Confusion_matrix на тестовой выборки = \n",
      "[[88 17]\n",
      " [35 39]]\n"
     ]
    }
   ],
   "source": [
    "metrics(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f5ec518",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "params = {'n_neighbors':[2,3,4,5]}\n",
    "name = 'sklearn_KNN()'\n",
    "grid = GridSearchCV(estimator=model,param_grid =params,cv=3 )  \n",
    "grid.fit(X_train,y_train)\n",
    "with open(name+'_best_params.txt', 'a') as f:\n",
    "    f.write(str(grid.best_estimator_))\n",
    "    \n",
    "pkl_filename = name+'_best_model.pkl'\n",
    "    \n",
    "with open(pkl_filename, 'wb') as file: \n",
    "    pickle.dump(grid.best_estimator_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9787da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верных ответов на обучающей выборки = 0.7851123595505618\n",
      "Доля верных ответов на тестовой выборки = 0.7039106145251397\n",
      "Recall_score на обучающей выборки = 0.6455223880597015\n",
      "Recall_score на тестовой выборки = 0.5405405405405406\n",
      "Precision_score на обучающей выборки = 0.7489177489177489\n",
      "Precision_score на тестовой выборки = 0.6779661016949152\n",
      "Roc_auc_score на обучающей выборки = 0.7574458787145354\n",
      "Roc_auc_score на тестовой выборки = 0.6797940797940798\n",
      "Confusion_matrix на обучающей выборки = \n",
      "[[386  58]\n",
      " [ 95 173]]\n",
      "Confusion_matrix на тестовой выборки = \n",
      "[[86 19]\n",
      " [34 40]]\n"
     ]
    }
   ],
   "source": [
    "metrics(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a56adf",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6f27fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop(['Survived'],axis=1), np.array(dataset['Survived']), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "440a3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier(BaseEstimator, ClassifierMixin):\n",
    "   \n",
    "    def calc_prior(self, features, target):\n",
    "        \n",
    "        self.prior = (features.groupby(target).apply(lambda x: len(x)) / self.rows).to_numpy()\n",
    "\n",
    "        return self.prior\n",
    "    \n",
    "    def calc_statistics(self, features, target):\n",
    "       \n",
    "        self.mean = features.groupby(target).apply(np.mean).to_numpy()\n",
    "        self.var = features.groupby(target).apply(np.var).to_numpy()\n",
    "              \n",
    "        return self.mean, self.var\n",
    "    \n",
    "    def gaussian_density(self, class_idx, x):     \n",
    "      \n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        numerator = np.exp((-1/2)*((x-mean)**2) / (2 * var))\n",
    "\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        prob = numerator / denominator\n",
    "        return prob\n",
    "    \n",
    "    def calc_posterior(self, x):\n",
    "        posteriors = []\n",
    "\n",
    "        for i in range(self.count):\n",
    "            prior = np.log(self.prior[i])\n",
    "            conditional = np.sum(np.log(self.gaussian_density(i, x)))\n",
    "            posterior = prior + conditional\n",
    "            posteriors.append(posterior)\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "     \n",
    "\n",
    "    def fit(self, features, target):\n",
    "        self.classes = np.unique(target)\n",
    "        self.count = len(self.classes)\n",
    "        self.feature_nums = features.shape[1]\n",
    "        self.rows = features.shape[0]\n",
    "        \n",
    "        self.calc_statistics(features, target)\n",
    "        self.calc_prior(features, target)\n",
    "        \n",
    "    def predict(self, features):\n",
    "        preds = [self.calc_posterior(f) for f in features.to_numpy()]\n",
    "        return preds\n",
    "\n",
    "    def accuracy(self, y_test, y_pred):\n",
    "        accuracy = np.sum(y_test == y_pred) / len(y_test)\n",
    "        return accuracy\n",
    "\n",
    "    def visualize(self, y_true, y_pred, target):\n",
    "        \n",
    "        tr = pd.DataFrame(data=y_true, columns=[target])\n",
    "        pr = pd.DataFrame(data=y_pred, columns=[target])\n",
    "        \n",
    "        \n",
    "        fig, ax = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(15,6))\n",
    "        \n",
    "        sns.countplot(x=target, data=tr, ax=ax[0], palette='viridis', alpha=0.7, hue=target, dodge=False)\n",
    "        sns.countplot(x=target, data=pr, ax=ax[1], palette='viridis', alpha=0.7, hue=target, dodge=False)\n",
    "        \n",
    "\n",
    "        fig.suptitle('True vs Predicted Comparison', fontsize=20)\n",
    "\n",
    "        ax[0].tick_params(labelsize=12)\n",
    "        ax[1].tick_params(labelsize=12)\n",
    "        ax[0].set_title(\"True values\", fontsize=18)\n",
    "        ax[1].set_title(\"Predicted values\", fontsize=18)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aa93d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayesClassifier()\n",
    "params = {}\n",
    "name = 'custom_NaiveBayesClassifier()'\n",
    "grid = GridSearchCV(estimator=model,param_grid =params,cv=3 )  \n",
    "grid.fit(X_train,y_train)\n",
    "with open(name+'_best_params.txt', 'a') as f:\n",
    "    f.write(str(grid.best_estimator_))\n",
    "    \n",
    "pkl_filename = name+'_best_model.pkl'\n",
    "    \n",
    "with open(pkl_filename, 'wb') as file: \n",
    "    pickle.dump(grid.best_estimator_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc70ed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верных ответов на обучающей выборки = 0.7120786516853933\n",
      "Доля верных ответов на тестовой выборки = 0.7262569832402235\n",
      "Recall_score на обучающей выборки = 0.3843283582089552\n",
      "Recall_score на тестовой выборки = 0.47297297297297297\n",
      "Precision_score на обучающей выборки = 0.7202797202797203\n",
      "Precision_score на тестовой выборки = 0.7777777777777778\n",
      "Roc_auc_score на обучающей выборки = 0.6471191340594326\n",
      "Roc_auc_score на тестовой выборки = 0.6888674388674388\n",
      "Confusion_matrix на обучающей выборки = \n",
      "[[404  40]\n",
      " [165 103]]\n",
      "Confusion_matrix на тестовой выборки = \n",
      "[[95 10]\n",
      " [39 35]]\n"
     ]
    }
   ],
   "source": [
    "metrics(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfd48015",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BernoulliNB()\n",
    "params = {}\n",
    "name = 'sklearn_NaiveBayesClassifier()'\n",
    "grid = GridSearchCV(estimator=model,param_grid =params,cv=3 )  \n",
    "grid.fit(X_train,y_train)\n",
    "with open(name+'_best_params.txt', 'a') as f:\n",
    "    f.write(str(grid.best_estimator_))\n",
    "    \n",
    "pkl_filename = name+'_best_model.pkl'\n",
    "    \n",
    "with open(pkl_filename, 'wb') as file: \n",
    "    pickle.dump(grid.best_estimator_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3be093d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля верных ответов на обучающей выборки = 0.7907303370786517\n",
      "Доля верных ответов на тестовой выборки = 0.7877094972067039\n",
      "Recall_score на обучающей выборки = 0.7238805970149254\n",
      "Recall_score на тестовой выборки = 0.7432432432432432\n",
      "Precision_score на обучающей выборки = 0.7211895910780669\n",
      "Precision_score на тестовой выборки = 0.7432432432432432\n",
      "Roc_auc_score на обучающей выборки = 0.7774808390480032\n",
      "Roc_auc_score на тестовой выборки = 0.7811454311454311\n",
      "Confusion_matrix на обучающей выборки = \n",
      "[[369  75]\n",
      " [ 74 194]]\n",
      "Confusion_matrix на тестовой выборки = \n",
      "[[86 19]\n",
      " [19 55]]\n"
     ]
    }
   ],
   "source": [
    "metrics(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63ab35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4db52f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f277c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3019d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6a4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
